{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and evaluate the cnn model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Tuple, Dict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_cifar100_data() -> Tuple[DataLoader, DataLoader]:\n",
    "    \"\"\"\n",
    "    Load and prepare CIFAR-100 dataset\n",
    "    \n",
    "    Returns:\n",
    "        Tuple containing train and test dataloaders\n",
    "    \"\"\"\n",
    "    # Define data transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))\n",
    "    ])\n",
    "\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))\n",
    "    ])\n",
    "\n",
    "    # Load datasets\n",
    "    trainset = torchvision.datasets.CIFAR100(\n",
    "        root=\"./data\", \n",
    "        train=True,\n",
    "        download=True, \n",
    "        transform=transform\n",
    "    )\n",
    "    \n",
    "    testset = torchvision.datasets.CIFAR100(\n",
    "        root=\"./data\", \n",
    "        train=False,\n",
    "        download=True, \n",
    "        transform=test_transform\n",
    "    )\n",
    "\n",
    "    # Create data loaders\n",
    "    trainloader = DataLoader(\n",
    "        trainset, \n",
    "        batch_size=128,\n",
    "        shuffle=True, \n",
    "        num_workers=2\n",
    "    )\n",
    "    \n",
    "    testloader = DataLoader(\n",
    "        testset, \n",
    "        batch_size=128,\n",
    "        shuffle=False, \n",
    "        num_workers=2\n",
    "    )\n",
    "\n",
    "    return trainloader, testloader\n",
    "\n",
    "def train_epoch(\n",
    "    model: nn.Module,\n",
    "    trainloader: DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    optimizer: optim.Optimizer,\n",
    "    device: torch.device\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Train model for one epoch\n",
    "    \n",
    "    Args:\n",
    "        model: CNN model to train\n",
    "        trainloader: Training data loader\n",
    "        criterion: Loss function\n",
    "        optimizer: Optimizer\n",
    "        device: Device to train on\n",
    "        \n",
    "    Returns:\n",
    "        Average training loss for the epoch\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, targets in trainloader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    return running_loss / len(trainloader)\n",
    "\n",
    "\n",
    "\n",
    "# Set training parameters\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_epochs = 200\n",
    "learning_rate = 0.1\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4\n",
    "\n",
    "# Initialize model, criterion, optimizer\n",
    "model = CNN(num_classes=100).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,\n",
    "    momentum=momentum,\n",
    "    weight_decay=weight_decay\n",
    ")\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "\n",
    "# Get data\n",
    "trainloader, testloader = get_cifar100_data()\n",
    "\n",
    "# Training loop\n",
    "train_losses = []\n",
    "test_metrics = []\n",
    "\n",
    "print(\"Starting training...\")\n",
    "for epoch in range(num_epochs):\n",
    "    # Train\n",
    "    train_loss = train_epoch(model, trainloader, criterion, optimizer, device)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Evaluate\n",
    "    metrics = evaluate(model, testloader, device)\n",
    "    test_metrics.append(metrics)\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}\")\n",
    "        print(f\"Test Loss: {metrics['loss']:.4f}\")\n",
    "        print(f\"Test Accuracy: {metrics['accuracy']:.2f}%\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Plot training curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot([m[\"loss\"] for m in test_metrics], label=\"Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot([m[\"accuracy\"] for m in test_metrics], label=\"Test Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
